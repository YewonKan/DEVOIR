{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YewonKan/DEVOIR/blob/master/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "6oKP_HiTWepz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libsndfile1-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGiPqghHWqgc",
        "outputId": "078bb022-a8ae-4d96-94c1-1e61e0a68792"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1-dev is already the newest version (1.0.31-2ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9pN10aKYMwm",
        "outputId": "320cd2e6-10d0-4014-ee76-51e15f134a63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pytorch/fairseq.git@main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMhQxAzkWuYL",
        "outputId": "54f87d28-b19b-4218-bd5e-2b7ed17bc8e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/pytorch/fairseq.git@main\n",
            "  Cloning https://github.com/pytorch/fairseq.git (to revision main) to /tmp/pip-req-build-nl2zzbk3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pytorch/fairseq.git /tmp/pip-req-build-nl2zzbk3\n",
            "  Resolved https://github.com/pytorch/fairseq.git to commit d13e14a800bb588e5a77fb4e551f554ff9b24a72\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (1.17.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (3.0.12)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.6 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.5-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.5 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.4 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/92/b1/4f3023143436f12c98bab53f0b3db617bd18a7d223627d5030e13a7b4fc2/omegaconf-2.0.4-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.3 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/29/08/a88210c2c1aa0a3f65f05d8a6c98939ccb84b6fb982aa6567dec4e6773f9/omegaconf-2.0.3-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.2 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/72/fe/f8d162aa059fb4f327fd75144dd69aa7e8acbb6d8d37013e4638c8490e0b/omegaconf-2.0.2-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.1 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/86/ec/605805e60abdb025b06664d107335031bb8ebdc52e0a90bdbad6a7130279/omegaconf-2.0.1-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading omegaconf-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2024.11.6)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (4.67.1)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fairseq==0.12.2) (24.2)\n",
            "Collecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Using cached omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.6 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached omegaconf-2.0.5-py3-none-any.whl.metadata (3.0 kB)\n",
            "\u001b[33mWARNING: Ignoring version 2.0.5 of omegaconf since it has invalid metadata:\n",
            "Requested omegaconf<2.1 from https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl (from fairseq==0.12.2) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    PyYAML (>=5.1.*)\n",
            "            ~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of hydra-core to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install fairseq and fairseq==0.12.2 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    fairseq 0.12.2 depends on omegaconf<2.1\n",
            "    hydra-core 1.0.7 depends on omegaconf<2.1 and >=2.0.5\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PbEB9AEdW7k3",
        "outputId": "bf872be4-536f-44fb-c0a4-b43f893249e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "7119722cfba74252acf7cc2de8acd21b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
        "\n",
        "class SSLModel(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(SSLModel, self).__init__()\n",
        "        self.processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
        "        self.model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\").to(device)\n",
        "        self.device = device\n",
        "        self.out_dim = self.model.config.hidden_size\n",
        "\n",
        "    def extract_feat(self, input_data):\n",
        "        if input_data.ndim == 3:\n",
        "            input_data = input_data.squeeze(1)\n",
        "        input_data = input_data.cpu().numpy()\n",
        "        inputs = self.processor(input_data, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state\n",
        "        return embeddings\n",
        "\n",
        "# Load configuration from JSON file\n",
        "with open(\"sample_data/AASIST.conf\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Extract model configuration\n",
        "args = config[\"model_config\"]\n",
        "\n",
        "# Initialize the model with Hugging Face-based SSLModel\n",
        "model = Wav2Vec2Model(args, device=device)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # attention map\n",
        "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
        "        self.att_weight = self._init_new_params(out_dim, 1)\n",
        "\n",
        "        # project\n",
        "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
        "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "        # batch norm\n",
        "        self.bn = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "        # dropout for inputs\n",
        "        self.input_drop = nn.Dropout(p=0.2)\n",
        "\n",
        "        # activate\n",
        "        self.act = nn.SELU(inplace=True)\n",
        "\n",
        "        # temperature\n",
        "        self.temp = 1.\n",
        "        if \"temperature\" in kwargs:\n",
        "            self.temp = kwargs[\"temperature\"]\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x   :(#bs, #node, #dim)\n",
        "        '''\n",
        "        # apply input dropout\n",
        "        x = self.input_drop(x)\n",
        "\n",
        "        # derive attention map\n",
        "        att_map = self._derive_att_map(x)\n",
        "\n",
        "        # projection\n",
        "        x = self._project(x, att_map)\n",
        "\n",
        "        # apply batch norm\n",
        "        x = self._apply_BN(x)\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "    def _pairwise_mul_nodes(self, x):\n",
        "        '''\n",
        "        Calculates pairwise multiplication of nodes.\n",
        "        - for attention map\n",
        "        x           :(#bs, #node, #dim)\n",
        "        out_shape   :(#bs, #node, #node, #dim)\n",
        "        '''\n",
        "\n",
        "        nb_nodes = x.size(1)\n",
        "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
        "        x_mirror = x.transpose(1, 2)\n",
        "\n",
        "        return x * x_mirror\n",
        "\n",
        "    def _derive_att_map(self, x):\n",
        "        '''\n",
        "        x           :(#bs, #node, #dim)\n",
        "        out_shape   :(#bs, #node, #node, 1)\n",
        "        '''\n",
        "        att_map = self._pairwise_mul_nodes(x)\n",
        "        # size: (#bs, #node, #node, #dim_out)\n",
        "        att_map = torch.tanh(self.att_proj(att_map))\n",
        "        # size: (#bs, #node, #node, 1)\n",
        "        att_map = torch.matmul(att_map, self.att_weight)\n",
        "\n",
        "        # apply temperature\n",
        "        att_map = att_map / self.temp\n",
        "\n",
        "        att_map = F.softmax(att_map, dim=-2)\n",
        "\n",
        "        return att_map\n",
        "\n",
        "    def _project(self, x, att_map):\n",
        "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
        "        x2 = self.proj_without_att(x)\n",
        "\n",
        "        return x1 + x2\n",
        "\n",
        "    def _apply_BN(self, x):\n",
        "        org_size = x.size()\n",
        "        x = x.view(-1, org_size[-1])\n",
        "        x = self.bn(x)\n",
        "        x = x.view(org_size)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _init_new_params(self, *size):\n",
        "        out = nn.Parameter(torch.FloatTensor(*size))\n",
        "        nn.init.xavier_normal_(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class HtrgGraphAttentionLayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj_type1 = nn.Linear(in_dim, in_dim)\n",
        "        self.proj_type2 = nn.Linear(in_dim, in_dim)\n",
        "\n",
        "        # attention map\n",
        "        self.att_proj = nn.Linear(in_dim, out_dim)\n",
        "        self.att_projM = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "        self.att_weight11 = self._init_new_params(out_dim, 1)\n",
        "        self.att_weight22 = self._init_new_params(out_dim, 1)\n",
        "        self.att_weight12 = self._init_new_params(out_dim, 1)\n",
        "        self.att_weightM = self._init_new_params(out_dim, 1)\n",
        "\n",
        "        # project\n",
        "        self.proj_with_att = nn.Linear(in_dim, out_dim)\n",
        "        self.proj_without_att = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "        self.proj_with_attM = nn.Linear(in_dim, out_dim)\n",
        "        self.proj_without_attM = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "        # batch norm\n",
        "        self.bn = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "        # dropout for inputs\n",
        "        self.input_drop = nn.Dropout(p=0.2)\n",
        "\n",
        "        # activate\n",
        "        self.act = nn.SELU(inplace=True)\n",
        "\n",
        "        # temperature\n",
        "        self.temp = 1.\n",
        "        if \"temperature\" in kwargs:\n",
        "            self.temp = kwargs[\"temperature\"]\n",
        "\n",
        "    def forward(self, x1, x2, master=None):\n",
        "        '''\n",
        "        x1  :(#bs, #node, #dim)\n",
        "        x2  :(#bs, #node, #dim)\n",
        "        '''\n",
        "        #print('x1',x1.shape)\n",
        "        #print('x2',x2.shape)\n",
        "        num_type1 = x1.size(1)\n",
        "        num_type2 = x2.size(1)\n",
        "        #print('num_type1',num_type1)\n",
        "        #print('num_type2',num_type2)\n",
        "        x1 = self.proj_type1(x1)\n",
        "        #print('proj_type1',x1.shape)\n",
        "        x2 = self.proj_type2(x2)\n",
        "        #print('proj_type2',x2.shape)\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "        #print('Concat x1 and x2',x.shape)\n",
        "\n",
        "        if master is None:\n",
        "            master = torch.mean(x, dim=1, keepdim=True)\n",
        "            #print('master',master.shape)\n",
        "        # apply input dropout\n",
        "        x = self.input_drop(x)\n",
        "\n",
        "        # derive attention map\n",
        "        att_map = self._derive_att_map(x, num_type1, num_type2)\n",
        "        #print('master',master.shape)\n",
        "        # directional edge for master node\n",
        "        master = self._update_master(x, master)\n",
        "        #print('master',master.shape)\n",
        "        # projection\n",
        "        x = self._project(x, att_map)\n",
        "        #print('proj x',x.shape)\n",
        "        # apply batch norm\n",
        "        x = self._apply_BN(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        x1 = x.narrow(1, 0, num_type1)\n",
        "        #print('x1',x1.shape)\n",
        "        x2 = x.narrow(1, num_type1, num_type2)\n",
        "        #print('x2',x2.shape)\n",
        "        return x1, x2, master\n",
        "\n",
        "    def _update_master(self, x, master):\n",
        "\n",
        "        att_map = self._derive_att_map_master(x, master)\n",
        "        master = self._project_master(x, master, att_map)\n",
        "\n",
        "        return master\n",
        "\n",
        "    def _pairwise_mul_nodes(self, x):\n",
        "        '''\n",
        "        Calculates pairwise multiplication of nodes.\n",
        "        - for attention map\n",
        "        x           :(#bs, #node, #dim)\n",
        "        out_shape   :(#bs, #node, #node, #dim)\n",
        "        '''\n",
        "\n",
        "        nb_nodes = x.size(1)\n",
        "        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n",
        "        x_mirror = x.transpose(1, 2)\n",
        "\n",
        "        return x * x_mirror\n",
        "\n",
        "    def _derive_att_map_master(self, x, master):\n",
        "        '''\n",
        "        x           :(#bs, #node, #dim)\n",
        "        out_shape   :(#bs, #node, #node, 1)\n",
        "        '''\n",
        "        att_map = x * master\n",
        "        att_map = torch.tanh(self.att_projM(att_map))\n",
        "\n",
        "        att_map = torch.matmul(att_map, self.att_weightM)\n",
        "\n",
        "        # apply temperature\n",
        "        att_map = att_map / self.temp\n",
        "\n",
        "        att_map = F.softmax(att_map, dim=-2)\n",
        "\n",
        "        return att_map\n",
        "\n",
        "    def _derive_att_map(self, x, num_type1, num_type2):\n",
        "        '''\n",
        "        x           :(#bs, #node, #dim)\n",
        "        out_shape   :(#bs, #node, #node, 1)\n",
        "        '''\n",
        "        att_map = self._pairwise_mul_nodes(x)\n",
        "        # size: (#bs, #node, #node, #dim_out)\n",
        "        att_map = torch.tanh(self.att_proj(att_map))\n",
        "        # size: (#bs, #node, #node, 1)\n",
        "\n",
        "        att_board = torch.zeros_like(att_map[:, :, :, 0]).unsqueeze(-1)\n",
        "\n",
        "        att_board[:, :num_type1, :num_type1, :] = torch.matmul(\n",
        "            att_map[:, :num_type1, :num_type1, :], self.att_weight11)\n",
        "        att_board[:, num_type1:, num_type1:, :] = torch.matmul(\n",
        "            att_map[:, num_type1:, num_type1:, :], self.att_weight22)\n",
        "        att_board[:, :num_type1, num_type1:, :] = torch.matmul(\n",
        "            att_map[:, :num_type1, num_type1:, :], self.att_weight12)\n",
        "        att_board[:, num_type1:, :num_type1, :] = torch.matmul(\n",
        "            att_map[:, num_type1:, :num_type1, :], self.att_weight12)\n",
        "\n",
        "        att_map = att_board\n",
        "\n",
        "\n",
        "\n",
        "        # apply temperature\n",
        "        att_map = att_map / self.temp\n",
        "\n",
        "        att_map = F.softmax(att_map, dim=-2)\n",
        "\n",
        "        return att_map\n",
        "\n",
        "    def _project(self, x, att_map):\n",
        "        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n",
        "        x2 = self.proj_without_att(x)\n",
        "\n",
        "        return x1 + x2\n",
        "\n",
        "    def _project_master(self, x, master, att_map):\n",
        "\n",
        "        x1 = self.proj_with_attM(torch.matmul(\n",
        "            att_map.squeeze(-1).unsqueeze(1), x))\n",
        "        x2 = self.proj_without_attM(master)\n",
        "\n",
        "        return x1 + x2\n",
        "\n",
        "    def _apply_BN(self, x):\n",
        "        org_size = x.size()\n",
        "        x = x.view(-1, org_size[-1])\n",
        "        x = self.bn(x)\n",
        "        x = x.view(org_size)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _init_new_params(self, *size):\n",
        "        out = nn.Parameter(torch.FloatTensor(*size))\n",
        "        nn.init.xavier_normal_(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class GraphPool(nn.Module):\n",
        "    def __init__(self, k: float, in_dim: int, p: Union[float, int]):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.proj = nn.Linear(in_dim, 1)\n",
        "        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()\n",
        "        self.in_dim = in_dim\n",
        "\n",
        "    def forward(self, h):\n",
        "        Z = self.drop(h)\n",
        "        weights = self.proj(Z)\n",
        "        scores = self.sigmoid(weights)\n",
        "        new_h = self.top_k_graph(scores, h, self.k)\n",
        "\n",
        "        return new_h\n",
        "\n",
        "    def top_k_graph(self, scores, h, k):\n",
        "        \"\"\"\n",
        "        args\n",
        "        =====\n",
        "        scores: attention-based weights (#bs, #node, 1)\n",
        "        h: graph data (#bs, #node, #dim)\n",
        "        k: ratio of remaining nodes, (float)\n",
        "        returns\n",
        "        =====\n",
        "        h: graph pool applied data (#bs, #node', #dim)\n",
        "        \"\"\"\n",
        "        _, n_nodes, n_feat = h.size()\n",
        "        n_nodes = max(int(n_nodes * k), 1)\n",
        "        _, idx = torch.topk(scores, n_nodes, dim=1)\n",
        "        idx = idx.expand(-1, -1, n_feat)\n",
        "\n",
        "        h = h * scores\n",
        "        h = torch.gather(h, 1, idx)\n",
        "\n",
        "        return h\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Residual_block(nn.Module):\n",
        "    def __init__(self, nb_filts, first=False):\n",
        "        super().__init__()\n",
        "        self.first = first\n",
        "\n",
        "        if not self.first:\n",
        "            self.bn1 = nn.BatchNorm2d(num_features=nb_filts[0])\n",
        "        self.conv1 = nn.Conv2d(in_channels=nb_filts[0],\n",
        "                               out_channels=nb_filts[1],\n",
        "                               kernel_size=(2, 3),\n",
        "                               padding=(1, 1),\n",
        "                               stride=1)\n",
        "        self.selu = nn.SELU(inplace=True)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=nb_filts[1])\n",
        "        self.conv2 = nn.Conv2d(in_channels=nb_filts[1],\n",
        "                               out_channels=nb_filts[1],\n",
        "                               kernel_size=(2, 3),\n",
        "                               padding=(0, 1),\n",
        "                               stride=1)\n",
        "\n",
        "        if nb_filts[0] != nb_filts[1]:\n",
        "            self.downsample = True\n",
        "            self.conv_downsample = nn.Conv2d(in_channels=nb_filts[0],\n",
        "                                             out_channels=nb_filts[1],\n",
        "                                             padding=(0, 1),\n",
        "                                             kernel_size=(1, 3),\n",
        "                                             stride=1)\n",
        "\n",
        "        else:\n",
        "            self.downsample = False\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if not self.first:\n",
        "            out = self.bn1(x)\n",
        "            out = self.selu(out)\n",
        "        else:\n",
        "            out = x\n",
        "\n",
        "        #print('out',out.shape)\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        #print('aft conv1 out',out.shape)\n",
        "        out = self.bn2(out)\n",
        "        out = self.selu(out)\n",
        "        # print('out',out.shape)\n",
        "        out = self.conv2(out)\n",
        "        #print('conv2 out',out.shape)\n",
        "\n",
        "        if self.downsample:\n",
        "            identity = self.conv_downsample(identity)\n",
        "\n",
        "        out += identity\n",
        "        #out = self.mp(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Wav2Vec2Model(nn.Module):\n",
        "    def __init__(self, args,device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "\n",
        "        # AASIST parameters\n",
        "        filts = [128, [1, 32], [32, 32], [32, 64], [64, 64]]\n",
        "        gat_dims = [64, 32]\n",
        "        pool_ratios = [0.5, 0.5, 0.5, 0.5]\n",
        "        temperatures =  [2.0, 2.0, 100.0, 100.0]\n",
        "\n",
        "\n",
        "        ####\n",
        "        # create network wav2vec 2.0\n",
        "        ####\n",
        "        self.ssl_model = SSLModel(self.device)\n",
        "        self.LL = nn.Linear(self.ssl_model.out_dim, 128)\n",
        "\n",
        "        self.first_bn = nn.BatchNorm2d(num_features=1)\n",
        "        self.first_bn1 = nn.BatchNorm2d(num_features=64)\n",
        "        self.drop = nn.Dropout(0.5, inplace=True)\n",
        "        self.drop_way = nn.Dropout(0.2, inplace=True)\n",
        "        self.selu = nn.SELU(inplace=True)\n",
        "\n",
        "        # RawNet2 encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[2])),\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[3])),\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[4])),\n",
        "            nn.Sequential(Residual_block(nb_filts=filts[4])))\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=(1,1)),\n",
        "            nn.SELU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(128, 64, kernel_size=(1,1)),\n",
        "\n",
        "        )\n",
        "        # position encoding\n",
        "        self.pos_S = nn.Parameter(torch.randn(1, 42, filts[-1][-1]))\n",
        "\n",
        "        self.master1 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
        "        self.master2 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n",
        "\n",
        "        # Graph module\n",
        "        self.GAT_layer_S = GraphAttentionLayer(filts[-1][-1],\n",
        "                                               gat_dims[0],\n",
        "                                               temperature=temperatures[0])\n",
        "        self.GAT_layer_T = GraphAttentionLayer(filts[-1][-1],\n",
        "                                               gat_dims[0],\n",
        "                                               temperature=temperatures[1])\n",
        "        # HS-GAL layer\n",
        "        self.HtrgGAT_layer_ST11 = HtrgGraphAttentionLayer(\n",
        "            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n",
        "        self.HtrgGAT_layer_ST12 = HtrgGraphAttentionLayer(\n",
        "            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n",
        "        self.HtrgGAT_layer_ST21 = HtrgGraphAttentionLayer(\n",
        "            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n",
        "        self.HtrgGAT_layer_ST22 = HtrgGraphAttentionLayer(\n",
        "            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n",
        "\n",
        "        # Graph pooling layers\n",
        "        self.pool_S = GraphPool(pool_ratios[0], gat_dims[0], 0.3)\n",
        "        self.pool_T = GraphPool(pool_ratios[1], gat_dims[0], 0.3)\n",
        "        self.pool_hS1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
        "        self.pool_hT1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
        "\n",
        "        self.pool_hS2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
        "        self.pool_hT2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n",
        "\n",
        "        self.out_layer = nn.Linear(5 * gat_dims[1], 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #-------pre-trained Wav2ve  c model fine tunning ------------------------##\n",
        "        x_ssl_feat = self.ssl_model.extract_feat(x.squeeze(-1))\n",
        "        x = self.LL(x_ssl_feat) #(bs,frame_number,feat_out_dim)\n",
        "\n",
        "        # post-processing on front-end features\n",
        "        x = x.transpose(1, 2)   #(bs,feat_out_dim,frame_number)\n",
        "        x = x.unsqueeze(dim=1) # add channel\n",
        "        x = F.max_pool2d(x, (3, 3))\n",
        "        x = self.first_bn(x)\n",
        "        x = self.selu(x)\n",
        "\n",
        "        # RawNet2-based encoder\n",
        "        x = self.encoder(x)\n",
        "        x = self.first_bn1(x)\n",
        "        x = self.selu(x)\n",
        "\n",
        "        w = self.attention(x)\n",
        "\n",
        "        #------------SA for spectral feature-------------#\n",
        "        w1 = F.softmax(w,dim=-1)\n",
        "        m = torch.sum(x * w1, dim=-1)\n",
        "        e_S = m.transpose(1, 2) + self.pos_S\n",
        "\n",
        "        # graph module layer\n",
        "        gat_S = self.GAT_layer_S(e_S)\n",
        "        out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)\n",
        "\n",
        "        #------------SA for temporal feature-------------#\n",
        "        w2 = F.softmax(w,dim=-2)\n",
        "        m1 = torch.sum(x * w2, dim=-2)\n",
        "\n",
        "        e_T = m1.transpose(1, 2)\n",
        "\n",
        "        # graph module layer\n",
        "        gat_T = self.GAT_layer_T(e_T)\n",
        "        out_T = self.pool_T(gat_T)\n",
        "\n",
        "        # learnable master node\n",
        "        master1 = self.master1.expand(x.size(0), -1, -1)\n",
        "        master2 = self.master2.expand(x.size(0), -1, -1)\n",
        "\n",
        "        # inference 1\n",
        "        out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(\n",
        "            out_T, out_S, master=self.master1)\n",
        "\n",
        "        out_S1 = self.pool_hS1(out_S1)\n",
        "        out_T1 = self.pool_hT1(out_T1)\n",
        "\n",
        "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(\n",
        "            out_T1, out_S1, master=master1)\n",
        "        out_T1 = out_T1 + out_T_aug\n",
        "        out_S1 = out_S1 + out_S_aug\n",
        "        master1 = master1 + master_aug\n",
        "\n",
        "        # inference 2\n",
        "        out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(\n",
        "            out_T, out_S, master=self.master2)\n",
        "        out_S2 = self.pool_hS2(out_S2)\n",
        "        out_T2 = self.pool_hT2(out_T2)\n",
        "\n",
        "        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(\n",
        "            out_T2, out_S2, master=master2)\n",
        "        out_T2 = out_T2 + out_T_aug\n",
        "        out_S2 = out_S2 + out_S_aug\n",
        "        master2 = master2 + master_aug\n",
        "\n",
        "        out_T1 = self.drop_way(out_T1)\n",
        "        out_T2 = self.drop_way(out_T2)\n",
        "        out_S1 = self.drop_way(out_S1)\n",
        "        out_S2 = self.drop_way(out_S2)\n",
        "        master1 = self.drop_way(master1)\n",
        "        master2 = self.drop_way(master2)\n",
        "\n",
        "        out_T = torch.max(out_T1, out_T2)\n",
        "        out_S = torch.max(out_S1, out_S2)\n",
        "        master = torch.max(master1, master2)\n",
        "\n",
        "        # Readout operation\n",
        "        T_max, _ = torch.max(torch.abs(out_T), dim=1)\n",
        "        T_avg = torch.mean(out_T, dim=1)\n",
        "\n",
        "        S_max, _ = torch.max(torch.abs(out_S), dim=1)\n",
        "        S_avg = torch.mean(out_S, dim=1)\n",
        "\n",
        "        last_hidden = torch.cat(\n",
        "            [T_max, T_avg, S_max, S_avg, master.squeeze(1)], dim=1)\n",
        "\n",
        "        last_hidden = self.drop(last_hidden)\n",
        "        output = self.out_layer(last_hidden)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KkMxTlOUWfVc",
        "outputId": "247dad22-4556-4c85-9994-5d5f4cad92d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Wav2Vec2Model.__init__() got an unexpected keyword argument 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1441930382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Initialize the model with Hugging Face-based SSLModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Wav2Vec2Model.__init__() got an unexpected keyword argument 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RV-gNv7mWf3T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}